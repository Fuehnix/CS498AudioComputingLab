{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8624130a58a1421890db374bf937e45c",
     "grade": false,
     "grade_id": "cell-ddd711814a0e6e7b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# CS498PS - Lab 5: Microphone Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3aefdcec7be064b2a6fc01b52e087015",
     "grade": false,
     "grade_id": "cell-b55ac5d947f3a1c4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this lab we will perform some simple microphone array processing. We will use the sound below:\n",
    "\n",
    "[https://drive.google.com/uc?export=download&id=1emuGR4tlmemJ8RXSD1rWQwNx13h5X9VM ]\n",
    "\n",
    "This is a recording from an 8-channel array. The microphones were placed at a distance of 0.1 meters from each other, and two simultaneous sounding sources were recorded. In the rest of this lab you will have to find where the sources are, and beamform so that you focus on each one separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "945b027d9edcfa4067f894f60ec2308a",
     "grade": false,
     "grade_id": "cell-b93372079e135ec2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 1: Getting the Steering Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "44d723859b98aae14926f87908329c42",
     "grade": false,
     "grade_id": "cell-53f9dff75e54652a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In order to do any further processing on this array we will need to obtain a set of steering vectors. As you might recall the steering vectors encode the phase shift that each frequency undergoes between all the microphones of the array for a given source location.  Since we will be using a far-field model you will need to generate a steering vector for each frequency and source angle you want to check. We will assume that we will use 1024pt DFTs so that you need to generate steering vectors for 513 frequencies. You will also need to scan all angles from 0 to $\\pi$. Since we won’t be making a continuous scan you can instead use 50 uniformly-spaced angles in that range.\n",
    "\n",
    "Recall that the steering vector formula is:\n",
    "$$v(\\theta,m,k)=e^{-j\\frac{(m-1)\\cdot r \\cdot cos(\\theta)}{C} \\frac{2\\pi \\cdot k}{N}}$$\n",
    "\n",
    "where $N$ is the size of the DFT and $k$ is a frequency index, $R$ is the sample rate, $C$ the speed of sound (use 345 m/s), $r$ is the distance between the mics, $m$ is the mic index (1 to 8 in this case) and $\\theta$ is the angle to check. Start by computing this with a simple triple loop, and later on revisit it and see if you can think of a simpler way to generate $v$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "# !{sys.executable} -m pip install scipy\n",
    "# from platform import python_version\n",
    "# print(sys.executable)\n",
    "# print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a23fa769f5b60a99db6c9319ea55631",
     "grade": true,
     "grade_id": "cell-970c9c980ba7dac2",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.        +0.j          0.        +0.j          0.        +0.j\n",
      "  ...  0.        +0.j          0.        +0.j\n",
      "   0.        +0.j        ]\n",
      " [ 1.        +0.j          1.        +0.j          1.        +0.j\n",
      "  ...  1.        +0.j          1.        +0.j\n",
      "   1.        +0.j        ]\n",
      " [ 1.        +0.j          0.99984562+0.017571j    0.99938252+0.03513657j\n",
      "  ... -0.8946685 +0.44673065j -0.90237988+0.43094146j\n",
      "  -0.90981264+0.41501922j]\n",
      " ...\n",
      " [ 1.        +0.j          0.99614284+0.08774652j  0.9846011 +0.17481613j\n",
      "  ...  0.67778238+0.73526257j  0.61065133+0.79189958j\n",
      "   0.53880952+0.84242763j]\n",
      " [ 1.        +0.j          0.99444725+0.1052362j   0.97785069+0.2093037j\n",
      "  ... -0.93485487-0.35503009j -0.89230184-0.45143928j\n",
      "  -0.83983937-0.542835j  ]\n",
      " [ 1.        +0.j          0.99244463+0.12269338j  0.96989267+0.24353277j\n",
      "  ...  0.99498803-0.09999408j  0.99973914+0.02283986j\n",
      "   0.98938343+0.14532867j]]\n",
      "[[ 0.        +0.j          0.        +0.j          0.        +0.j\n",
      "  ...  0.        +0.j          0.        +0.j\n",
      "   0.        +0.j        ]\n",
      " [ 1.        +0.j          1.        +0.j          1.        +0.j\n",
      "  ...  1.        +0.j          1.        +0.j\n",
      "   1.        +0.j        ]\n",
      " [ 1.        +0.j          0.99923113-0.0392065j   0.9969257 -0.07835271j\n",
      "  ...  0.40767879-0.9131254j   0.37156489-0.92840699j\n",
      "   0.33487961-0.94226092j]\n",
      " ...\n",
      " [ 1.        +0.j          0.98083729-0.19482866j  0.92408359-0.38219043j\n",
      "  ...  0.86343503+0.50446006j  0.94517255+0.32657134j\n",
      "   0.99068595+0.13616665j]\n",
      " [ 1.        +0.j          0.9724446 -0.23313406j  0.89129702-0.45341992j\n",
      "  ...  0.81263944-0.58276679j  0.65438405-0.75616236j\n",
      "   0.46006504-0.88788522j]\n",
      " [ 1.        +0.j          0.96255655-0.27108096j  0.85303022-0.52186151j\n",
      "  ... -0.2008433 -0.97962338j -0.45888028-0.88849811j\n",
      "  -0.68255314-0.73083596j]]\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "import numpy as np\n",
    "import math\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.wavfile as wavfile\n",
    "speedOfSound = 345\n",
    "radianMin = 0 #0\n",
    "radianMax = 180 #pi\n",
    "r = 0.1\n",
    "micMin = 1\n",
    "micMax = 9\n",
    "Nfreq = 513\n",
    "DFTSize = 1024\n",
    "rate, file = wavfile.read('array.wav')\n",
    "# IPython.display.display( IPython.display.Audio( file, rate=rate))\n",
    "\n",
    "#load file and get sampling rate\n",
    "v = np.zeros((radianMax, micMax, Nfreq), dtype=complex)\n",
    "for theta in range(radianMin,radianMax):\n",
    "    for m in range(micMin, micMax):\n",
    "        for k in range(0,Nfreq):\n",
    "            v[theta,m,k] = np.exp(-1j*(((m-1)*r*math.cos(theta))/speedOfSound)*((2*np.pi*k)/DFTSize)*rate)\n",
    "print(v[90])\n",
    "print(v[0])\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1071848410f894a8085e43cb163fa056",
     "grade": false,
     "grade_id": "cell-ab2eb212372fc093",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 2: Localization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0afca9c9b7f40d39140e1ad186b2caee",
     "grade": false,
     "grade_id": "cell-77497bc5d3d4e8cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now that we have the steering vectors we can perform some localization. In order to find where the sources are we will make a beamformer that “focuses” at each angle that we want to check and then returns the amount of acoustic energy that emanates from that point. Wherever there is a source we will see an energy bump. In order to perform the beamforming we will need to undo the phase shifts that are imposed on a sound from each angle. If we do so, for a signal that emanates from that angle we will appropriately phase shift the inputs so that they are perfectly synchronized over all channels. If we have the desired source perfectly synchronized over all channels and we add them together we will boost that source by a factor of 8 (the number of microphones). If this synchrony is not present we will get a lesser boost.\n",
    "\n",
    "In order to undo the phase shift we simply need to apply the inverse steering vectors on the input. Perform an STFT of each channel with 1024 frequencies, a hop size of 256 and a Hann window (I hope you have already finished our code from Lab 1!). In order to apply the necessary phase shift on each channel you need to multiply each STFT spectrum (i.e. each column of the STFT output) with the conjugate of the steering vector that corresponds to its microphone $m$ and the angle $\\theta$ that you want to measure. For each angle you want to measure, do this over all the microphones and sum the resulting spectrograms from all the channels. Once you do that measure the mean squared value of this sum and this will be your response from angle $\\theta$. Do this over all angles and plot the overall response. The peaks of the resulting plot will reveal to you where the sources are.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T01:46:22.311669Z",
     "start_time": "2020-02-27T01:46:22.307349Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b3359a37b62ad4cdb0d77483fcc6c45",
     "grade": true,
     "grade_id": "cell-2c7913fc273ef7b0",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "rate, file = wavfile.read('crumble.wav')\n",
    "def stft(input_sound, dft_size, hop_size, zero_pad, window):\n",
    "    # YOUR CODE HERE\n",
    "    padNum = math.ceil((len(input_sound)/dft_size)*dft_size-len(input_sound))\n",
    "    pad = list(input_sound) + list (padNum*[0])\n",
    "    pad = [0]*dft_size + pad + [0]*dft_size\n",
    "    tempMatrix = []\n",
    "    for i in range(0, len(pad)-dft_size+1, hop_size):\n",
    "        tempMatrix.append(pad[i:i+dft_size]*window)\n",
    "    return np.fft.rfft(tempMatrix, dft_size+zero_pad, axis=1) \n",
    "\n",
    "def istft( stft_output, dft_size, hop_size, zero_pad, window):\n",
    "    # YOUR CODE HERE\n",
    "    segments = np.fft.irfft(stft_output, axis=1)\n",
    "    input_sound = []\n",
    "    for i in range (0, len(stft_output), dft_size//hop_size):\n",
    "        input_sound += list(segments[i]/window)\n",
    "    input_sound = input_sound[:-zero_pad]\n",
    "    return input_sound\n",
    "\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dft_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f1d62a643078>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minput_sound\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m16\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mstftResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdft_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdft_size\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0minverseResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mistft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstftResult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdft_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdft_size\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dft_size' is not defined"
     ]
    }
   ],
   "source": [
    "sample_rate, input_sound = wavfile.read('./crumble.wav')\n",
    "# sample_rate, input_sound = scipy.io.wavfile.read('./piano.wav')\n",
    "# sample_rate, input_sound = scipy.io.wavfile.read('./speech.wav')\n",
    "input_sound = input_sound.astype('float64')\n",
    "input_sound /= 2**16 - 1\n",
    "\n",
    "stftResult = stft(input_sound, dft_size, dft_size // 4, zero_pad, window)\n",
    "inverseResult = istft(stftResult, dft_size, dft_size // 4, zero_pad, window)\n",
    "\n",
    "sound(input_sound,rate=sample_rate, label='Original')\n",
    "sound(inverseResult,rate=sample_rate, label='Inverse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "84028363c997c8666b8c186b7be01445",
     "grade": false,
     "grade_id": "cell-7ab5b98fdf1ad53f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 3: Beamforming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd8cb68b3235991bee2f27d62b6b7c24",
     "grade": false,
     "grade_id": "cell-b59c754cb96f5b79",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Identify the angle of the two sources by looking at the peaks from the above result. Let’s call these $\\theta_1$ and $\\theta_2$. Now that you know where you want to focus the array, you can design two beamformers to focus on the two sources. The steering vectors that you need to use will be $v(\\theta_1,:,:)$ and $v(\\theta_2,:,:)$. Just as before you need to take each channel’s STFT, multiply each column with the conjugate of the steering vector that corresponds to all the channels and the selected angle to focus on, and then you simply add them all up. The resulting sum will the STFT of the focused output. Use your inverse STFT function to take this back to the time domain and verify that it indeed sounds better than any of the input channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e48cc10dcd64b877944d6f5666619319",
     "grade": true,
     "grade_id": "cell-3f7df5275259ff35",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
